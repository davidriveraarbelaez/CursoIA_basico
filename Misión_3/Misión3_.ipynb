{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXnRobyFiDPaBrkFsVmy/S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidriveraarbelaez/IA_Explorador/blob/main/Misi%C3%B3n3_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Descarga del Conjunto de Datos:\n",
        "\n",
        "*  Accede al conjunto de datos en [Kaggle](https://www.kaggle.com/datasets/datafiniti/consumer-reviews-of-amazon-products).\n",
        "*  Inicia sesión en tu cuenta de Kaggle y descarga el archivo CSV correspondiente."
      ],
      "metadata": {
        "id": "YQAVFxIkf6Wb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Carga del Conjunto de Datos en Jupyter Notebook:\n",
        "\n",
        "*  Utiliza la biblioteca **pandas** para cargar el archivo CSV en un DataFrame"
      ],
      "metadata": {
        "id": "T756dalxgRm_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVQaEyePfw_n",
        "outputId": "b333a34c-8e5d-46f1-c9b6-bdf524c01548"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     id             dateAdded           dateUpdated  \\\n",
            "0  AVqVGZNvQMlgsOJE6eUY  2017-03-03T16:56:05Z  2018-10-25T16:36:31Z   \n",
            "1  AVqVGZNvQMlgsOJE6eUY  2017-03-03T16:56:05Z  2018-10-25T16:36:31Z   \n",
            "2  AVqVGZNvQMlgsOJE6eUY  2017-03-03T16:56:05Z  2018-10-25T16:36:31Z   \n",
            "3  AVqVGZNvQMlgsOJE6eUY  2017-03-03T16:56:05Z  2018-10-25T16:36:31Z   \n",
            "4  AVqVGZNvQMlgsOJE6eUY  2017-03-03T16:56:05Z  2018-10-25T16:36:31Z   \n",
            "\n",
            "                                                name       asins   brand  \\\n",
            "0  Amazon Kindle E-Reader 6\" Wifi (8th Generation...  B00ZV9PXP2  Amazon   \n",
            "1  Amazon Kindle E-Reader 6\" Wifi (8th Generation...  B00ZV9PXP2  Amazon   \n",
            "2  Amazon Kindle E-Reader 6\" Wifi (8th Generation...  B00ZV9PXP2  Amazon   \n",
            "3  Amazon Kindle E-Reader 6\" Wifi (8th Generation...  B00ZV9PXP2  Amazon   \n",
            "4  Amazon Kindle E-Reader 6\" Wifi (8th Generation...  B00ZV9PXP2  Amazon   \n",
            "\n",
            "                                          categories primaryCategories  \\\n",
            "0  Computers,Electronics Features,Tablets,Electro...       Electronics   \n",
            "1  Computers,Electronics Features,Tablets,Electro...       Electronics   \n",
            "2  Computers,Electronics Features,Tablets,Electro...       Electronics   \n",
            "3  Computers,Electronics Features,Tablets,Electro...       Electronics   \n",
            "4  Computers,Electronics Features,Tablets,Electro...       Electronics   \n",
            "\n",
            "                                           imageURLs  \\\n",
            "0  https://pisces.bbystatic.com/image2/BestBuy_US...   \n",
            "1  https://pisces.bbystatic.com/image2/BestBuy_US...   \n",
            "2  https://pisces.bbystatic.com/image2/BestBuy_US...   \n",
            "3  https://pisces.bbystatic.com/image2/BestBuy_US...   \n",
            "4  https://pisces.bbystatic.com/image2/BestBuy_US...   \n",
            "\n",
            "                                                keys  ...  \\\n",
            "0  allnewkindleereaderblack6glarefreetouchscreend...  ...   \n",
            "1  allnewkindleereaderblack6glarefreetouchscreend...  ...   \n",
            "2  allnewkindleereaderblack6glarefreetouchscreend...  ...   \n",
            "3  allnewkindleereaderblack6glarefreetouchscreend...  ...   \n",
            "4  allnewkindleereaderblack6glarefreetouchscreend...  ...   \n",
            "\n",
            "                                    reviews.dateSeen reviews.doRecommend  \\\n",
            "0  2018-05-27T00:00:00Z,2017-09-18T00:00:00Z,2017...               False   \n",
            "1  2018-05-27T00:00:00Z,2017-07-07T00:00:00Z,2017...                True   \n",
            "2                               2018-05-27T00:00:00Z                True   \n",
            "3                               2018-10-09T00:00:00Z                True   \n",
            "4                               2018-05-27T00:00:00Z                True   \n",
            "\n",
            "    reviews.id reviews.numHelpful reviews.rating  \\\n",
            "0          NaN                  0              3   \n",
            "1          NaN                  0              5   \n",
            "2          NaN                  0              4   \n",
            "3  177283626.0                  3              5   \n",
            "4          NaN                  0              5   \n",
            "\n",
            "                                  reviews.sourceURLs  \\\n",
            "0  http://reviews.bestbuy.com/3545/5442403/review...   \n",
            "1  http://reviews.bestbuy.com/3545/5442403/review...   \n",
            "2  https://reviews.bestbuy.com/3545/5442403/revie...   \n",
            "3  https://redsky.target.com/groot-domain-api/v1/...   \n",
            "4  https://reviews.bestbuy.com/3545/5442403/revie...   \n",
            "\n",
            "                                        reviews.text  \\\n",
            "0  I thought it would be as big as small paper bu...   \n",
            "1  This kindle is light and easy to use especiall...   \n",
            "2  Didnt know how much i'd use a kindle so went f...   \n",
            "3  I am 100 happy with my purchase. I caught it o...   \n",
            "4  Solid entry level Kindle. Great for kids. Gift...   \n",
            "\n",
            "                                  reviews.title  reviews.username  \\\n",
            "0                                     Too small            llyyue   \n",
            "1  Great light reader. Easy to use at the beach            Charmi   \n",
            "2                           Great for the price      johnnyjojojo   \n",
            "3                                   A Great Buy           Kdperry   \n",
            "4      Solid entry-level Kindle. Great for kids       Johnnyblack   \n",
            "\n",
            "                                          sourceURLs  \n",
            "0  https://www.newegg.com/Product/Product.aspx%25...  \n",
            "1  https://www.newegg.com/Product/Product.aspx%25...  \n",
            "2  https://www.newegg.com/Product/Product.aspx%25...  \n",
            "3  https://www.newegg.com/Product/Product.aspx%25...  \n",
            "4  https://www.newegg.com/Product/Product.aspx%25...  \n",
            "\n",
            "[5 rows x 24 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Cargar el conjunto de datos\n",
        "df = pd.read_csv('/content/Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products.csv')\n",
        "\n",
        "# Mostrar las primeras filas del DataFrame\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Tokenización:\n",
        "\n",
        "Emplea nltk para dividir el texto en tokens:"
      ],
      "metadata": {
        "id": "qR6C5QXpgcrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Descargar recursos necesarios\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Tokenizar una reseña de ejemplo\n",
        "ejemplo = df['reviews.text'][0]\n",
        "tokens = word_tokenize(ejemplo.lower())\n",
        "print(tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJfRzB2SgfOh",
        "outputId": "13f2a3ab-3ebc-446e-dea9-3fbab9f3e6d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'thought', 'it', 'would', 'be', 'as', 'big', 'as', 'small', 'paper', 'but', 'turn', 'out', 'to', 'be', 'just', 'like', 'my', 'palm', '.', 'i', 'think', 'it', 'is', 'too', 'small', 'to', 'read', 'on', 'it', '...', 'not', 'very', 'comfortable', 'as', 'regular', 'kindle', '.', 'would', 'definitely', 'recommend', 'a', 'paperwhite', 'instead', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Normalización:\n",
        "\n",
        "Convierte el texto a minúsculas y elimina caracteres especiales:"
      ],
      "metadata": {
        "id": "fhXxNLoJiJha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def normalizar(texto):\n",
        "    # Convertir a minúsculas\n",
        "    texto = texto.lower()\n",
        "    # Eliminar caracteres especiales y números\n",
        "    texto = re.sub(r'[^a-záéíóúüñ\\s]', '', texto)\n",
        "    return texto\n",
        "\n",
        "df['texto_normalizado'] = df['reviews.text'].apply(normalizar)\n"
      ],
      "metadata": {
        "id": "m4K5fQaMgmhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Eliminación de Stopwords:\n",
        "\n",
        "Utiliza **nltk** para eliminar palabras comunes que no aportan valor semántico:"
      ],
      "metadata": {
        "id": "oCVyNA3sgowO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Descargar lista de stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def eliminar_stopwords(texto):\n",
        "    tokens = word_tokenize(texto)\n",
        "    tokens_filtrados = [t for t in tokens if t not in stop_words]\n",
        "    return ' '.join(tokens_filtrados)\n",
        "\n",
        "df['texto_sin_stopwords'] = df['texto_normalizado'].apply(eliminar_stopwords)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tH0T1AQvgt9E",
        "outputId": "af1e6f77-09ce-48ef-f76f-436408405453"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Lematización:\n",
        "\n",
        "Aplica WordNetLemmatizer de nltk para reducir las palabras a su forma base:"
      ],
      "metadata": {
        "id": "2bru-gvjgxbz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Descargar recursos necesarios\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lematizar(texto):\n",
        "    tokens = word_tokenize(texto)\n",
        "    tokens_lematizados = [lemmatizer.lemmatize(t) for t in tokens]\n",
        "    return ' '.join(tokens_lematizados)\n",
        "\n",
        "df['texto_lematizado'] = df['texto_sin_stopwords'].apply(lematizar)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3jrxlGEgvxU",
        "outputId": "e88a48ef-d3cf-491c-c95f-311d1d4cce53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Stemming:\n",
        "\n",
        "Alternativamente, utiliza **PorterStemmer** para reducir las palabras a su raíz:"
      ],
      "metadata": {
        "id": "Nl_a-G9rg39k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def aplicar_stemming(texto):\n",
        "    tokens = word_tokenize(texto)\n",
        "    tokens_stemmizados = [stemmer.stem(t) for t in tokens]\n",
        "    return ' '.join(tokens_stemmizados)\n",
        "\n",
        "df['texto_stemmizado'] = df['texto_sin_stopwords'].apply(aplicar_stemming)\n"
      ],
      "metadata": {
        "id": "MWZN_o3Bg7iX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Representación de Texto:\n",
        "\n",
        "*  Bolsa de Palabras (Bag of Words):\n",
        "\n",
        "  *  Utiliza CountVectorizer de **sklearn**:"
      ],
      "metadata": {
        "id": "pBJ8wereg-gZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "X_bow = vectorizer.fit_transform(df['texto_lematizado'])\n"
      ],
      "metadata": {
        "id": "kleTUVaPhFSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  TF-IDF:\n",
        "\n",
        "  *  Aplica TfidfVectorizer de sklearn:"
      ],
      "metadata": {
        "id": "rUpbp3NVhH-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(df['texto_lematizado'])\n"
      ],
      "metadata": {
        "id": "QYnAbwPohL0c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}